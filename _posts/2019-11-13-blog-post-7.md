---
title: 'Pytorch学习笔记'
date: 2019-10-25
permalink: /posts/2019/10/blog-post-8/
tags:
  - pytorch
  - numpy
  - matplotlib
---

Pytorch学习笔记


#### numpy 和 pytorch对比


```python
import numpy as np
import torch
from torch.autograd import Variable
%matplotlib inline
```


```python
np_data = np.arange(6).reshape((2,3))
np_data
```




    array([[0, 1, 2],
           [3, 4, 5]])




```python
torch_data = torch.from_numpy(np_data)
torch_data
```




    tensor([[0, 1, 2],
            [3, 4, 5]])




```python
tensor2array = torch_data.numpy()
tensor2array
```




    array([[0, 1, 2],
           [3, 4, 5]])




```python
# abs
data = [-1, -2, 1, 2]
tensor = torch.FloatTensor(data)
print('numpy',np.abs(data),'\ntorch',torch.abs(tensor))
```

    numpy [1 2 1 2] 
    torch tensor([1., 2., 1., 2.])



```python
# sin
data = [-1, -2, 1, 2]
tensor = torch.FloatTensor(data)
print('numpy',np.sin(data),'\ntorch',torch.sin(tensor))
```

    numpy [-0.84147098 -0.90929743  0.84147098  0.90929743] 
    torch tensor([-0.8415, -0.9093,  0.8415,  0.9093])



```python
# mean
data = [-1, -2, 1, 2]
tensor = torch.FloatTensor(data)
print('numpy',np.mean(data),'\ntorch',torch.mean(tensor))
```

    numpy 0.0 
    torch tensor(0.)



```python
# matrix
data = [[1,2],[3,4]]
tensor = torch.FloatTensor(data)  # 32-bot floating point
data = np.array(data)
```


```python
# 矩阵相乘
print(
'\nnumpy:',np.matmul(data,data),
    '\ntorch:',torch.mm(tensor,tensor)
)
```

    
    numpy: [[ 7 10]
     [15 22]] 
    torch: tensor([[ 7., 10.],
            [15., 22.]])



```python
# 矩阵相乘
tensor = torch.FloatTensor([1,2,3,4])  # torch的dot只可以接收1D数据
print(
'\nnumpy:',data.dot(data),
    '\ntorch:',tensor.dot(tensor)
)
```

    
    numpy: [[ 7 10]
     [15 22]] 
    torch: tensor(30.)


#### variable 变量


```python
tensor = torch.FloatTensor([[1,2],[3,4]])
variable = Variable(tensor, requires_grad=True)  # required 一般为Flase  True计算误差反向传播，神经网络节点会计算梯度
```


```python
t_out = torch.mean(tensor*tensor)  # x^2

v_out = torch.mean(variable*variable)  # 会反向传播

print(t_out,v_out)

v_out.backward()  # variable的梯度  v_out = 1/4*sum(var*var)

print(variable.grad)  # 打印梯度     d(v_out)/d(var) = 1/4 * 2 * variable = variable/2

print(variable)

print(variable.data)  # 是一个tensor

print(variable.data.numpy)  # 转化为numpy
```

    tensor(7.5000) tensor(7.5000, grad_fn=<MeanBackward0>)
    tensor([[0.5000, 1.0000],
            [1.5000, 2.0000]])
    tensor([[1., 2.],
            [3., 4.]], requires_grad=True)
    tensor([[1., 2.],
            [3., 4.]])
    <built-in method numpy of Tensor object at 0x129fa4fc0>


#### pytorch 的激活函数使用


```python
import torch
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
```


```python
# fake data
x = torch.linspace(-5, 5, 200)  # x data(tensor),shape(200,1)
x = Variable(x)
x_np = x.data.numpy()
```


```python
# 画图只能用numpy数据
y_relu = F.relu(x).data.numpy()
y_sigmoid = F.sigmoid(x).data.numpy()
y_tanh = F.tanh(x).data.numpy()
y_softplus = F.softplus(x).data.numpy()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
      warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
      warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")



```python
plt.figure(1,figsize=(8,6))
plt.subplot(221)
plt.plot(x_np,y_relu,c='red',label='relu')
plt.ylim(-1, 5)
plt.legend(loc='best')

plt.figure(1,figsize=(8,6))
plt.subplot(222)
plt.plot(x_np,y_sigmoid,c='red',label='sigmoid')
plt.ylim(-0.2, 1.2)
plt.legend(loc='best')

plt.figure(1,figsize=(8,6))
plt.subplot(223)
plt.plot(x_np,y_tanh,c='red',label='tanh')
plt.ylim(-1.2, 1.2)
plt.legend(loc='best')

plt.figure(1,figsize=(8,6))
plt.subplot(224)
plt.plot(x_np,y_softplus,c='red',label='softplus')
plt.ylim(-0.2, 6)
plt.legend(loc='best')
```




    <matplotlib.legend.Legend at 0x13056be48>



    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_18_2.png)


#### 回归


```python
import torch
from torch.autograd import Variable
import torch.nn.functional as F
import matplotlib.pyplot as plt
```


```python
# fake data
x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1) # x data(tensor) shape=(100,1)  unsqueeze是把一维变成二维
y = x.pow(2) + 0.2 * torch.rand(x.size())  # noisy y data(tensor) shape=(100,1)

```


```python
x, y = Variable(x), Variable(y)
```


```python
plt.scatter(x.data.numpy(),y.data.numpy())
plt.show()
```


![png](https://shinkeika.github.io/images/output_23_0.png)



```python
class Net(torch.nn.Module):
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()
        self.hidden = torch.nn.Linear(n_feature, n_hidden)
        self.predict = torch.nn.Linear(n_hidden, n_output)
    
    def forward(self, x):
        # 搭建神经网络
        x = F.relu(self.hidden(x))
        x = self.predict(x)
        return x
```


```python
net = Net(1,10,1)
print(net)  # 打印网络结构
```

    Net(
      (hidden): Linear(in_features=1, out_features=10, bias=True)
      (predict): Linear(in_features=10, out_features=1, bias=True)
    )



```python
plt.ion()   # something about plotting
```


```python
optimizer = torch.optim.SGD(net.parameters(), lr=0.5)  # 优化函数
loss_func = torch.nn.MSELoss()  # 均方差处理回归问题
```


```python
for t in range(100):
    # 预测
    prediction = net(x)
    # 损失函数
    loss = loss_func(prediction, y)  # 预测值在前
    
    optimizer.zero_grad()
    # 反向传播误差
    loss.backward()
    # 优化梯度
    optimizer.step()
    
    if t % 10 == 0:
        # plot and show learning process
        plt.cla()
        plt.scatter(x.data.numpy(), y.data.numpy())
        plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)
        plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})
        plt.show()
        plt.pause(0.1)

plt.ioff()
    
```


![png](https://shinkeika.github.io/images/output_28_0.png)



![png](https://shinkeika.github.io/images/output_28_1.png)



![png](https://shinkeika.github.io/images/output_28_2.png)



![png](https://shinkeika.github.io/images/output_28_3.png)



![png](https://shinkeika.github.io/images/output_28_4.png)



![png](https://shinkeika.github.io/images/output_28_5.png)



![png](https://shinkeika.github.io/images/output_28_6.png)



![png](https://shinkeika.github.io/images/output_28_7.png)



![png](https://shinkeika.github.io/images/output_28_8.png)



![png](https://shinkeika.github.io/images/output_28_9.png)


#### Classification


```python
import torch
from torch.autograd import Variable
import torch.nn.functional as F
import matplotlib.pyplot as plt
```


```python
# make fake data
n_data = torch.ones(100, 2)
x0 = torch.normal(2*n_data, 1)      # class0 x data (tensor), shape=(100, 2)
y0 = torch.zeros(100)               # class0 y data (tensor), shape=(100, 1)
x1 = torch.normal(-2*n_data, 1)     # class1 x data (tensor), shape=(100, 2)
y1 = torch.ones(100)                # class1 y data (tensor), shape=(100, 1)
x = torch.cat((x0, x1), 0).type(torch.FloatTensor)  # shape (200, 2) FloatTensor = 32-bit floating
y = torch.cat((y0, y1), ).type(torch.LongTensor)    # shape (200,) LongTensor = 64-bit integer
x,y  = Variable(x), Variable(y)
```


```python
plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=y.data.numpy(), s=100, lw=0, cmap='RdYlGn')
plt.show()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_32_1.png)



```python
class Net(torch.nn.Module):
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()
        self.hidden = torch.nn.Linear(n_feature, n_hidden)
        self.out = torch.nn.Linear(n_hidden, n_output)
    
    def forward(self, x):
        # 搭建神经网络
        x = F.relu(self.hidden(x))
        x = self.out(x)
        return x
```


```python
net = Net(2,10,2)
print(net)
```

    Net(
      (hidden): Linear(in_features=2, out_features=10, bias=True)
      (out): Linear(in_features=10, out_features=2, bias=True)
    )



```python
optimizer = torch.optim.SGD(net.parameters(), lr=0.5)
loss_func = torch.nn.CrossEntropyLoss()
```


```python
for t in range(100):
    out = net(x)                 # input x and predict based on x
    loss = loss_func(out, y)     # must be (1. nn output, 2. target), the target label is NOT one-hotted

    optimizer.zero_grad()   # clear gradients for next train
    loss.backward()         # backpropagation, compute gradients
    optimizer.step()        # apply gradients
    
    if t % 10 == 0 or t in [3, 6]:
        # plot and show learning process
        plt.cla()
        _, prediction = torch.max(F.softmax(out), 1)
        pred_y = prediction.data.numpy().squeeze()
        target_y = y.data.numpy()
        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn')
        accuracy = sum(pred_y == target_y)/200.
        plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color':  'red'})
        plt.show()
        plt.pause(0.1)

plt.ioff()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
      if sys.path[0] == '':
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_36_1.png)



![png](https://shinkeika.github.io/images/output_36_2.png)



![png](https://shinkeika.github.io/images/output_36_3.png)



![png](https://shinkeika.github.io/images/output_36_4.png)



![png](https://shinkeika.github.io/images/output_36_5.png)



![png](https://shinkeika.github.io/images/output_36_6.png)



![png](https://shinkeika.github.io/images/output_36_7.png)



![png](https://shinkeika.github.io/images/output_36_8.png)



![png](https://shinkeika.github.io/images/output_36_9.png)



![png](https://shinkeika.github.io/images/output_36_10.png)



![png](https://shinkeika.github.io/images/output_36_11.png)



![png](https://shinkeika.github.io/images/output_36_12.png)


#### 快速搭建法


```python
net2 = torch.nn.Sequential(
torch.nn.Linear(2, 10),
torch.nn.ReLU(),  # Relu开头大写表示为Relu为一个类
torch.nn.Linear(10, 2),
)
print(net2)
```

    Sequential(
      (0): Linear(in_features=2, out_features=10, bias=True)
      (1): ReLU()
      (2): Linear(in_features=10, out_features=2, bias=True)
    )


#### 保存


```python
x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)
y = x.pow(2) + 0.2*torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)
x, y = Variable(x, requires_grad=False), Variable(y, requires_grad=False)
```


```python
def save():
    net1 = torch.nn.Sequential(
    torch.nn.Linear(1, 10),
    torch.nn.ReLU(),  # Relu开头大写表示为Relu为一个类
    torch.nn.Linear(10, 1),
    )
    optimizer = torch.optim.SGD(net1.parameters(), lr=0.5)
    loss_func = torch.nn.MSELoss()
    for t in range(100):
        prediction = net1(x)
        loss = loss_func(prediction, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
    plt.figure(1, figsize=(10, 3))
    plt.subplot(131)
    plt.title('Net1')
    plt.scatter(x.data.numpy(), y.data.numpy())
    plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)
    
    torch.save(net1, 'net1.pkl')  # 保存整个神经网络
    torch.save(net1.state_dict(), 'net_params.pkl')  # 只保存参数
    
    
def restore_net():
    net2 = torch.load('net1.pkl')
    prediction = net2(x)
    
    plt.subplot(132)
    plt.title('Net2')
    plt.scatter(x.data.numpy(), y.data.numpy())
    plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)
    
def restore_params():
    net3 = torch.nn.Sequential(
    torch.nn.Linear(1, 10),
    torch.nn.ReLU(),  # Relu开头大写表示为Relu为一个类
    torch.nn.Linear(10, 1),
    )
    # 比提取整个神经网络更快
    net3.load_state_dict(torch.load('net_params.pkl'))
    prediction = net3(x)
    
    # plot result
    plt.subplot(133)
    plt.title('Net3')
    plt.scatter(x.data.numpy(), y.data.numpy())
    plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)
    plt.show()
```


```python
save()
restore_net()
restore_params()
```


![png](https://shinkeika.github.io/images/output_42_0.png)


#### 批训练


```python
import torch
import torch.utils.data as Data
```


```python
BATCH_SIZE = 8
x = torch.linspace(1, 10, 10)
y = torch.linspace(10, 1, 10)
```


```python
torch_dataset = Data.TensorDataset(x,y)
loader = Data.DataLoader(
    dataset=torch_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,  # 是否打乱
    num_workers=2,  # 用几个线程，进程
)

for epoch in range(3):
    for step, (batch_x, batch_y) in enumerate(loader):  # loader enumrate 表示每次提取给一个索引
        # training...
        print('Epoch:',epoch,'| Step:',step,'| batch x:',batch_x.numpy(),
             '| batch y:',batch_y.numpy()
             )
        
# 如果不够一次batch 那么就只用剩下的，不做任何改变
```

    Epoch: 0 | Step: 0 | batch x: [ 8.  9.  1.  7.  5.  2.  6. 10.] | batch y: [ 3.  2. 10.  4.  6.  9.  5.  1.]
    Epoch: 0 | Step: 1 | batch x: [4. 3.] | batch y: [7. 8.]
    Epoch: 1 | Step: 0 | batch x: [ 3. 10.  4.  5.  2.  6.  9.  1.] | batch y: [ 8.  1.  7.  6.  9.  5.  2. 10.]
    Epoch: 1 | Step: 1 | batch x: [8. 7.] | batch y: [3. 4.]
    Epoch: 2 | Step: 0 | batch x: [8. 4. 2. 7. 6. 3. 1. 5.] | batch y: [ 3.  7.  9.  4.  5.  8. 10.  6.]
    Epoch: 2 | Step: 1 | batch x: [10.  9.] | batch y: [1. 2.]


#### 加速训练
1. SGD (Stochastic Gradient Descent) 每次只用批量数据
2. Momentum 喝醉了的人
3. AdaGrad 改动学习率。鞋子成了走弯路的阻力
4. RMSProp 结合Momentum AdaGrad


```python
import torch
import torch.utils.data as Data
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
%matplotlib inline
LR = 0.01
BATCH_SIZE = 32
EPOCH = 12
```


```python
# fake dataset
x = torch.unsqueeze(torch.linspace(-1, 1, 1000), dim=1)
y = x.pow(2) + 0.1*torch.normal(torch.zeros(*x.size()))

# plot dataset
plt.scatter(x.numpy(), y.numpy())
plt.show()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_49_1.png)



```python
torch_dataset = Data.TensorDataset(x, y)
loader = Data.DataLoader(
    dataset=torch_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=True, num_workers=2,)
```


```python
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.hidden = torch.nn.Linear(1, 20)   # hidden layer
        self.predict = torch.nn.Linear(20, 1)   # output layer

    def forward(self, x):
        x = F.relu(self.hidden(x))      # activation function for hidden layer
        x = self.predict(x)             # linear output
        return x
```


```python
net_SGD         = Net()
net_Momentum    = Net()
net_RMSprop     = Net()
net_Adam        = Net()
nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]
```


```python
opt_SGD         = torch.optim.SGD(net_SGD.parameters(), lr=LR)
opt_Momentum    = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)
opt_RMSprop     = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)
opt_Adam        = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))
optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]
```


```python
loss_func = torch.nn.MSELoss()
losses_his = [[], [], [], []]   # record loss
```


```python
# training
for epoch in range(EPOCH):
    print('Epoch: ', epoch)
    for step, (batch_x, batch_y) in enumerate(loader):          # for each training step
        b_x = Variable(batch_x)
        b_y = Variable(batch_y)

        for net, opt, l_his in zip(nets, optimizers, losses_his):
            output = net(b_x)              # get output for every net
            loss = loss_func(output, b_y)  # compute loss for every net
            opt.zero_grad()                # clear gradients for next train
            loss.backward()                # backpropagation, compute gradients
            opt.step()                     # apply gradients
            l_his.append(loss.item())     # loss recoder

labels = ['SGD', 'Momentum', 'RMSprop', 'Adam']

for i, l_his in enumerate(losses_his):
    plt.plot(l_his, label=labels[i])
    
plt.legend(loc='best')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.ylim((0, 0.2))
plt.show()
```

    Epoch:  0
    Epoch:  1
    Epoch:  2
    Epoch:  3
    Epoch:  4
    Epoch:  5
    Epoch:  6
    Epoch:  7
    Epoch:  8
    Epoch:  9
    Epoch:  10
    Epoch:  11



![png](https://shinkeika.github.io/images/output_55_1.png)


#### CNN


```python
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.utils.data as Data
import torchvision
import matplotlib.pyplot as plt
```


```python
EPOCH = 1
BATCH_SIZE = 50
LR = 0.001
DOWNLOAD_MNIST = True
```


```python
train_data = torchvision.datasets.MNIST(root='./mnist',
                                        train=True,
                                        transform=torchvision.transforms.ToTensor(),  #(0-255)->(0,1)
                                        download=DOWNLOAD_MNIST
                                       )
```

    0it [00:00, ?it/s]

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz


    100%|█████████▉| 9863168/9912422 [00:19<00:00, 749181.46it/s]

    Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw


    
    0it [00:00, ?it/s][A

    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz


    
      0%|          | 0/28881 [00:00<?, ?it/s][A
     57%|█████▋    | 16384/28881 [00:00<00:00, 63814.03it/s][A
    
    0it [00:00, ?it/s][A[A

    Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz


    
    
      0%|          | 0/1648877 [00:00<?, ?it/s][A[A
    
      1%|          | 16384/1648877 [00:00<00:26, 62374.44it/s][A[A
    
      2%|▏         | 40960/1648877 [00:00<00:22, 70229.04it/s][A[A
    
      6%|▌         | 98304/1648877 [00:01<00:17, 86448.88it/s][A[A
    
      9%|▉         | 147456/1648877 [00:01<00:17, 88064.82it/s][A[A
    
     11%|█▏        | 188416/1648877 [00:02<00:14, 104128.84it/s][A[A
    
     18%|█▊        | 303104/1648877 [00:02<00:09, 136739.45it/s][A[A
    
     22%|██▏       | 368640/1648877 [00:02<00:07, 162349.47it/s][A[A
    
     26%|██▋       | 434176/1648877 [00:02<00:06, 187208.23it/s][A[A
    
     31%|███▏      | 516096/1648877 [00:02<00:05, 218899.96it/s][A[A
    
     36%|███▋      | 598016/1648877 [00:03<00:04, 247898.84it/s][A[A
    
     42%|████▏     | 688128/1648877 [00:03<00:03, 278884.72it/s][A[A
    
     48%|████▊     | 786432/1648877 [00:03<00:02, 312262.01it/s][A[A
    
     54%|█████▎    | 884736/1648877 [00:03<00:02, 339952.00it/s][A[A
    
     60%|██████    | 991232/1648877 [00:04<00:01, 369723.45it/s][A[A
    
     66%|██████▌   | 1089536/1648877 [00:04<00:01, 444016.58it/s][A[A
    
     70%|██████▉   | 1146880/1648877 [00:04<00:01, 456772.53it/s][A[A
    
     73%|███████▎  | 1204224/1648877 [00:04<00:01, 381331.96it/s][A[A
    
     80%|███████▉  | 1318912/1648877 [00:04<00:00, 410776.71it/s][A[A
    
     87%|████████▋ | 1433600/1648877 [00:04<00:00, 435938.72it/s][A[A
    
    1654784it [00:05, 315220.49it/s]                             [A[A
    
    
    0it [00:00, ?it/s][A[A

    Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz


    
    
    8192it [00:00, 16191.71it/s]            [A[A

    Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw
    Processing...
    Done!


    



```python
# plot one example
print(train_data.train_data.size())                 # (60000, 28, 28)
print(train_data.train_labels.size())               # (60000)
plt.imshow(train_data.train_data[0].numpy(), cmap='gray')
plt.title('%i' % train_data.train_labels[0])
plt.show()
```

    torch.Size([60000, 28, 28])
    torch.Size([60000])


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data
      warnings.warn("train_data has been renamed data")
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets
      warnings.warn("train_labels has been renamed targets")



![png](https://shinkeika.github.io/images/output_60_2.png)


    9920512it [00:30, 749181.46it/s]                             
    32768it [00:20, 63814.03it/s]                           [A


```python
train_loader = Data.DataLoader(train_data,batch_size=BATCH_SIZE, shuffle=True)
test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)  # 提取testdata
test_x = Variable(torch.unsqueeze(test_data.test_data,dim=1),
                  volatile=True).type(torch.FloatTensor)[:2000]/255.  # 归一化
test_y = test_data.test_labels[:2000]
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data
      warnings.warn("test_data has been renamed data")
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
      after removing the cwd from sys.path.
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets
      warnings.warn("test_labels has been renamed targets")



```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(  # input_shape = (1, 28, 28)
            nn.Conv2d(
                in_channels=1,
                out_channels=16,
                kernel_size=5,
                stride=1,
                padding=2,
            ),  # https://shinkeika.github.io/images/output_shape = (16, 28, 28)
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),  # https://shinkeika.github.io/images/output_shape = (16, 14, 14)
            )
        self.conv2 = nn.Sequential(
            nn.Conv2d(16,32,5,1,2),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.out = nn.Linear(32 * 7 * 7, 10)
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)  # (batch, 32, 7, 7)
        x = x.view(x.size(0), -1)
        output = self.out(x)
        return output, x
```


```python
cnn = CNN()
print(cnn)
```

    CNN(
      (conv1): Sequential(
        (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (conv2): Sequential(
        (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (out): Linear(in_features=1568, out_features=10, bias=True)
    )



```python
optimizer = torch.optim.Adam(cnn.parameters(),lr=LR)
loss_func = nn.CrossEntropyLoss()
```


```python
from matplotlib import cm
try: from sklearn.manifold import TSNE; HAS_SK = True
except: HAS_SK = False; print('Please install sklearn for layer visualization')
def plot_with_labels(lowDWeights, labels):
    plt.cla()
    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]
    for x, y, s in zip(X, Y, labels):
        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)
    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)

plt.ion()


for epoch in range(EPOCH):
    for step, (x, y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader
        b_x = Variable(x)   # batch x
        b_y = Variable(y)   # batch y

        output = cnn(b_x)[0]            # cnn output
        loss = loss_func(output, b_y)   # cross entropy loss
        optimizer.zero_grad()           # clear gradients for this training step
        loss.backward()                 # backpropagation, compute gradients
        optimizer.step()                # apply gradients

        if step % 100 == 0:
            test_output, last_layer = cnn(test_x)
            pred_y = torch.max(test_output, 1)[1].data.squeeze()
            accuracy = float((pred_y.numpy() == test_y.numpy()).astype(int).sum()) / float(test_y.size(0))
            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)
            if HAS_SK:
                # Visualization of trained flatten layer (T-SNE)
                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)
                plot_only = 500
                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])
                labels = test_y.numpy()[:plot_only]
                plot_with_labels(low_dim_embs, labels)
plt.ioff()
```

    Epoch:  0 | train loss: 0.0023 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_2.png)


    Epoch:  0 | train loss: 0.0002 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_5.png)


    Epoch:  0 | train loss: 0.0096 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_8.png)


    Epoch:  0 | train loss: 0.0021 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_11.png)


    Epoch:  0 | train loss: 0.0071 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_14.png)


    Epoch:  0 | train loss: 0.0300 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_17.png)


    Epoch:  0 | train loss: 0.0078 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_20.png)


    Epoch:  0 | train loss: 0.0032 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_23.png)


    Epoch:  0 | train loss: 0.0002 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_26.png)


    Epoch:  0 | train loss: 0.0029 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_29.png)


    Epoch:  0 | train loss: 0.0054 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_32.png)


    Epoch:  0 | train loss: 0.0001 | test accuracy: 0.99


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_65_35.png)



```python
# print 10 predictions from test data
test_output, _ = cnn(test_x[:10])
pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()
print(pred_y, 'prediction number')
print(test_y[:10].numpy(), 'real number')
```

    [7 2 1 0 4 1 4 9 5 9] prediction number
    [7 2 1 0 4 1 4 9 5 9] real number


#### RNN classification


```python
import torch
from torch import nn
from torch.autograd import Variable
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
%matplotlib inline
```


```python
EPOCH = 1  # train the training data n times
BATCH_SIZE = 64
TIME_SIZE = 28  # image height
INPUT_SIZE = 28  # image weight
LR = 0.01
DOWNLOAD_MNIST = True
```


```python
train_data = dsets.MNIST(root='./mnist',
                                        train=True,
                                        transform= transforms.ToTensor(),  #(0-255)->(0,1)
                                        download=DOWNLOAD_MNIST
                                       )
```


```python
# plot one example
print(train_data.train_data.size())     # (60000, 28, 28)
print(train_data.train_labels.size())   # (60000)
plt.imshow(train_data.train_data[0].numpy(), cmap='gray')
plt.title('%i' % train_data.train_labels[0])
plt.show()
```

    torch.Size([60000, 28, 28])
    torch.Size([60000])


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data
      warnings.warn("train_data has been renamed data")
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets
      warnings.warn("train_labels has been renamed targets")



![png](https://shinkeika.github.io/images/output_71_2.png)



```python
train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE,
                                          shuffle=True
                                         )
test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())
```


```python
print(test_data.test_data.shape)
```

    torch.Size([10000, 28, 28])



```python
test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)
test_y = test_data.test_labels.numpy().squeeze()[:2000]
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
      """Entry point for launching an IPython kernel.
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets
      warnings.warn("test_labels has been renamed targets")



```python

```


```python
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()
        
        self.rnn = nn.LSTM(input_size=INPUT_SIZE,
                          hidden_size = 64,
                          num_layers = 1,
                           batch_first=True,  # input和output会把batch_size当作第一维度
                           #  (batch, time_step, input_size)
                          )
        self.out = nn.Linear(64, 10)
    def forward(self, x):
        # x_shape (batch, time_step, input_size)
        # r_out shape (batch, time_step, https://shinkeika.github.io/images/output_size)
        # h_n shape(n_layers, batch, hidden_size)
        # h_c shape (n_layers, batch, hidden_size)
        r_out, (h_n, h_c) = self.rnn(x, None)  # None 表示没有第一个hidden state  h_n, h_c 分线程，主线程的hidden state
        
        # choose r_out at the last time step
        out = self.out(r_out[:, -1, :])  # (batch, time step, input)
        return out
        
        
rnn = RNN()
print(rnn)
```

    RNN(
      (rnn): LSTM(28, 64, batch_first=True)
      (out): Linear(in_features=64, out_features=10, bias=True)
    )



```python
optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)
loss_func = nn.CrossEntropyLoss()  # target 不是onehot.而是是多少就是多少
```


```python
for epoch in range(EPOCH):
    for step, (b_x, b_y) in enumerate(train_loader):
        b_x = b_x.view(-1, 28, 28)             # reshape x to (batch, time_step, input_size)
        output = rnn(b_x)                               # rnn output
        loss = loss_func(output, b_y)                   # cross entropy loss
        optimizer.zero_grad()                           # clear gradients for this training step
        loss.backward()                                 # backpropagation, compute gradients
        optimizer.step()
        
        if step % 50 == 0:
            test_output = rnn(test_x)   # (samples, time_step, input_size)
            pred_y = torch.max(test_output, 1)[1].data.numpy()
            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)
            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)


# print 10 predictions from test data
test_output = rnn(test_x[:10].view(-1, 28, 28))
pred_y = torch.max(test_output, 1)[1].data.numpy()
print(pred_y, 'prediction number')
print(test_y[:10], 'real number')
```

    Epoch:  0 | train loss: 2.2813 | test accuracy: 0.12
    Epoch:  0 | train loss: 1.2089 | test accuracy: 0.50
    Epoch:  0 | train loss: 0.9069 | test accuracy: 0.68
    Epoch:  0 | train loss: 0.3751 | test accuracy: 0.80
    Epoch:  0 | train loss: 0.4286 | test accuracy: 0.84
    Epoch:  0 | train loss: 0.2151 | test accuracy: 0.88
    Epoch:  0 | train loss: 0.3728 | test accuracy: 0.89
    Epoch:  0 | train loss: 0.3291 | test accuracy: 0.90
    Epoch:  0 | train loss: 0.1752 | test accuracy: 0.92
    Epoch:  0 | train loss: 0.1449 | test accuracy: 0.92
    Epoch:  0 | train loss: 0.2426 | test accuracy: 0.95
    Epoch:  0 | train loss: 0.1053 | test accuracy: 0.94
    Epoch:  0 | train loss: 0.1136 | test accuracy: 0.94
    Epoch:  0 | train loss: 0.0354 | test accuracy: 0.95
    Epoch:  0 | train loss: 0.1584 | test accuracy: 0.95
    Epoch:  0 | train loss: 0.1284 | test accuracy: 0.95
    Epoch:  0 | train loss: 0.2670 | test accuracy: 0.94
    Epoch:  0 | train loss: 0.1241 | test accuracy: 0.94
    Epoch:  0 | train loss: 0.1312 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.2468 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.0821 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.1575 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.1150 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.1226 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.1412 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.0729 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.0593 | test accuracy: 0.95
    Epoch:  1 | train loss: 0.0621 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.1346 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.0474 | test accuracy: 0.94
    Epoch:  1 | train loss: 0.0331 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.0526 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.1713 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.0887 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.2398 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.2013 | test accuracy: 0.96
    Epoch:  1 | train loss: 0.1144 | test accuracy: 0.97
    Epoch:  1 | train loss: 0.1673 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.3019 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1005 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1898 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0712 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1976 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0163 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0690 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0802 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.0520 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.0404 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1290 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0973 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0557 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.0841 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1294 | test accuracy: 0.98
    Epoch:  2 | train loss: 0.0167 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.0305 | test accuracy: 0.97
    Epoch:  2 | train loss: 0.1745 | test accuracy: 0.96
    Epoch:  2 | train loss: 0.0660 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0191 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0155 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0902 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0237 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0302 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0425 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.1179 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0991 | test accuracy: 0.95
    Epoch:  3 | train loss: 0.0321 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0723 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0442 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0461 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0960 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.1802 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0817 | test accuracy: 0.96
    Epoch:  3 | train loss: 0.0156 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0540 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0615 | test accuracy: 0.97
    Epoch:  3 | train loss: 0.0348 | test accuracy: 0.98
    Epoch:  4 | train loss: 0.0796 | test accuracy: 0.98
    Epoch:  4 | train loss: 0.0612 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0365 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0120 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.1354 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0107 | test accuracy: 0.96
    Epoch:  4 | train loss: 0.0856 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0846 | test accuracy: 0.96
    Epoch:  4 | train loss: 0.0088 | test accuracy: 0.96
    Epoch:  4 | train loss: 0.1433 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.1243 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.1052 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0512 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0095 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0183 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0276 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.0853 | test accuracy: 0.96
    Epoch:  4 | train loss: 0.1854 | test accuracy: 0.97
    Epoch:  4 | train loss: 0.1002 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0035 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0555 | test accuracy: 0.96
    Epoch:  5 | train loss: 0.0933 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0298 | test accuracy: 0.98
    Epoch:  5 | train loss: 0.0259 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0401 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0322 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0115 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0713 | test accuracy: 0.96
    Epoch:  5 | train loss: 0.0674 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0601 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.1173 | test accuracy: 0.96
    Epoch:  5 | train loss: 0.0429 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0613 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0217 | test accuracy: 0.98
    Epoch:  5 | train loss: 0.0637 | test accuracy: 0.96
    Epoch:  5 | train loss: 0.1125 | test accuracy: 0.97
    Epoch:  5 | train loss: 0.0605 | test accuracy: 0.96
    Epoch:  5 | train loss: 0.2573 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.0063 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.1179 | test accuracy: 0.96
    Epoch:  6 | train loss: 0.0220 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.0282 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0624 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.1970 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0476 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0882 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.1055 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.1034 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0172 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0135 | test accuracy: 0.96
    Epoch:  6 | train loss: 0.0378 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.1232 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.0109 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.1533 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.0061 | test accuracy: 0.98
    Epoch:  6 | train loss: 0.0439 | test accuracy: 0.97
    Epoch:  6 | train loss: 0.0558 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0154 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0434 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0866 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0424 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0985 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0106 | test accuracy: 0.96
    Epoch:  7 | train loss: 0.2070 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0049 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0691 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0198 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0475 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0365 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0147 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.1001 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0640 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.0107 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.0295 | test accuracy: 0.97
    Epoch:  7 | train loss: 0.1713 | test accuracy: 0.98
    Epoch:  7 | train loss: 0.1161 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0214 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0077 | test accuracy: 0.98
    Epoch:  8 | train loss: 0.0235 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0120 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.1612 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0970 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.1794 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0045 | test accuracy: 0.98
    Epoch:  8 | train loss: 0.0981 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0209 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0440 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0262 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0885 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0172 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0923 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0424 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.1166 | test accuracy: 0.98
    Epoch:  8 | train loss: 0.0695 | test accuracy: 0.97
    Epoch:  8 | train loss: 0.0520 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0913 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0729 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0030 | test accuracy: 0.98
    Epoch:  9 | train loss: 0.0078 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0681 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0130 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0182 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0073 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0326 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0053 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0123 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.1010 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0230 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0745 | test accuracy: 0.98
    Epoch:  9 | train loss: 0.0305 | test accuracy: 0.98
    Epoch:  9 | train loss: 0.2428 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0483 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.2160 | test accuracy: 0.97
    Epoch:  9 | train loss: 0.0106 | test accuracy: 0.97
    [7 2 1 6 4 1 4 9 5 9] prediction number
    [7 2 1 0 4 1 4 9 5 9] real number


#### RNN regressor


```python
import numpy as np
import torch
from torch import nn
from torch.autograd import Variable
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
%matplotlib inline
```


```python
TIME_STEP = 10
INPUT_SIZE = 1
LR = 0.02
```


```python
steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor
x_np = np.sin(steps)
y_np = np.cos(steps)
plt.plot(steps, y_np, 'r-', label='target(cos)')
plt.plot(steps, x_np, 'b-', label='target(sin)')
plt.legend(loc='best')
plt.show()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_82_1.png)



```python
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()
        self.rnn = nn.RNN(
        input_size=INPUT_SIZE,  # 1
        hidden_size = 32,
        num_layers=1,
        batch_first=True
        )
        self.out = nn.Linear(32, 1)
        
    def forward(self, x, h_state):
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, hidden_size)
        r_out, h_state = self.rnn(x, h_state)
        outs = []
        for time_step in range(r_out.size(1)):
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state  # list 变成tensor形式

rnn = RNN()
print(rnn)
```

    RNN(
      (rnn): RNN(1, 32, batch_first=True)
      (out): Linear(in_features=32, out_features=1, bias=True)
    )



```python
optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)
loss_func = nn.MSELoss()
h_state = None      # for initial hidden state

plt.figure(1, figsize=(12, 5))
plt.ion()           # continuously plot
```


    <Figure size 864x360 with 0 Axes>



```python
for step in range(50):
    start, end = step * np.pi, (step + 1) * np.pi  # time steps
    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32)
    x_np = np.sin(steps)
    y_np = np.cos(steps)
    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])    # shape (batch, time_step, input_size) 增加一维
    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])
    prediction, h_state = rnn(x, h_state)   # rnn output
    # !! next step is important !!
    h_state = h_state.data        # repack the hidden state, break the connection from last iteration

    loss = loss_func(prediction, y)         # calculate loss
    optimizer.zero_grad()                   # clear gradients for this training step
    loss.backward()                         # backpropagation, compute gradients
    optimizer.step()                        # apply gradients

    # plotting
    plt.plot(steps, y_np.flatten(), 'r-')
    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')
    plt.draw(); plt.pause(0.05)

plt.ioff()
plt.show()
```


![png](https://shinkeika.github.io/images/output_85_0.png)



![png](https://shinkeika.github.io/images/output_85_1.png)



![png](https://shinkeika.github.io/images/output_85_2.png)



![png](https://shinkeika.github.io/images/output_85_3.png)



![png](https://shinkeika.github.io/images/output_85_4.png)



![png](https://shinkeika.github.io/images/output_85_5.png)



![png](https://shinkeika.github.io/images/output_85_6.png)



![png](https://shinkeika.github.io/images/output_85_7.png)



![png](https://shinkeika.github.io/images/output_85_8.png)



![png](https://shinkeika.github.io/images/output_85_9.png)



![png](https://shinkeika.github.io/images/output_85_10.png)



![png](https://shinkeika.github.io/images/output_85_11.png)



![png](https://shinkeika.github.io/images/output_85_12.png)



![png](https://shinkeika.github.io/images/output_85_13.png)



![png](https://shinkeika.github.io/images/output_85_14.png)



![png](https://shinkeika.github.io/images/output_85_15.png)



![png](https://shinkeika.github.io/images/output_85_16.png)



![png](https://shinkeika.github.io/images/output_85_17.png)



![png](https://shinkeika.github.io/images/output_85_18.png)



![png](https://shinkeika.github.io/images/output_85_19.png)



![png](https://shinkeika.github.io/images/output_85_20.png)



![png](https://shinkeika.github.io/images/output_85_21.png)



![png](https://shinkeika.github.io/images/output_85_22.png)



![png](https://shinkeika.github.io/images/output_85_23.png)



![png](https://shinkeika.github.io/images/output_85_24.png)



![png](https://shinkeika.github.io/images/output_85_25.png)



![png](https://shinkeika.github.io/images/output_85_26.png)



![png](https://shinkeika.github.io/images/output_85_27.png)



![png](https://shinkeika.github.io/images/output_85_28.png)



![png](https://shinkeika.github.io/images/output_85_29.png)



![png](https://shinkeika.github.io/images/output_85_30.png)



![png](https://shinkeika.github.io/images/output_85_31.png)



![png](https://shinkeika.github.io/images/output_85_32.png)



![png](https://shinkeika.github.io/images/output_85_33.png)



![png](https://shinkeika.github.io/images/output_85_34.png)



![png](https://shinkeika.github.io/images/output_85_35.png)



![png](https://shinkeika.github.io/images/output_85_36.png)



![png](https://shinkeika.github.io/images/output_85_37.png)



![png](https://shinkeika.github.io/images/output_85_38.png)



![png](https://shinkeika.github.io/images/output_85_39.png)



![png](https://shinkeika.github.io/images/output_85_40.png)



![png](https://shinkeika.github.io/images/output_85_41.png)



![png](https://shinkeika.github.io/images/output_85_42.png)



![png](https://shinkeika.github.io/images/output_85_43.png)



![png](https://shinkeika.github.io/images/output_85_44.png)



![png](https://shinkeika.github.io/images/output_85_45.png)



![png](https://shinkeika.github.io/images/output_85_46.png)



![png](https://shinkeika.github.io/images/output_85_47.png)



![png](https://shinkeika.github.io/images/output_85_48.png)



![png](https://shinkeika.github.io/images/output_85_49.png)


#### GAN


```python
import torch
import torch.nn as nn
from torch.autograd import Variable
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

torch.manual_seed(1)    # reproducible
np.random.seed(1)
```


```python
# Hyper Parameters
BATCH_SIZE = 64
LR_G = 0.0001           # learning rate for generator
LR_D = 0.0001           # learning rate for discriminator
N_IDEAS = 5             # think of this as number of ideas for generating an art work (Generator)
ART_COMPONENTS = 15     # it could be total point G can draw in the canvas
PAINT_POINTS = np.vstack([np.linspace(-1, 1, ART_COMPONENTS) for _ in range(BATCH_SIZE)])
```


```python
def artist_works():
    a = np.random.uniform(1,2,size=BATCH_SIZE)[:,np.newaxis]
    paintings = a * np.power(PAINT_POINTS, 2) + (a-1)
    paintings = torch.from_numpy(paintings).float()
    return Variable(paintings)
```


```python

```


```python
G = nn.Sequential(
    nn.Linear(N_IDEAS, 128),
    nn.ReLU(),
    nn.Linear(128,ART_COMPONENTS)
)
```


```python
D = nn.Sequential(
    nn.Linear(ART_COMPONENTS, 128),
    nn.ReLU(),
    nn.Linear(128, 1),
    nn.Sigmoid(),
)
```


```python
opt_D = torch.optim.Adam(D.parameters(), lr=LR_D)
opt_G = torch.optim.Adam(G.parameters(), lr=LR_G)

for step in range(10000):
    artist_paintings = artist_works()
    G_ideas = Variable(torch.randn(BATCH_SIZE, N_IDEAS))
    G_paintings = G(G_ideas)
    
    prob_artist0 = D(artist_paintings)
    prob_artist1 = D(G_paintings)
    
    D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1. - prob_artist1))
    G_loss = torch.mean(torch.log(1. - prob_artist1))
    
    opt_D.zero_grad()
    D_loss.backward(retain_graph=True)
    opt_D.step()
    
    opt_G.zero_grad()
    G_loss.backward()
    opt_G.step()
    
    
    if step % 1000 == 0:  # plotting
        plt.cla()
        plt.plot(PAINT_POINTS[0], G_paintings.data.numpy()[0], c='#4AD631', lw=3, label='Generated painting',)
        plt.plot(PAINT_POINTS[0], 2 * np.power(PAINT_POINTS[0], 2) + 1, c='#74BCFF', lw=3, label='upper bound')
        plt.plot(PAINT_POINTS[0], 1 * np.power(PAINT_POINTS[0], 2) + 0, c='#FF9359', lw=3, label='lower bound')
        plt.text(-.5, 2.3, 'D accuracy=%.2f (0.5 for D to converge)' % prob_artist0.data.numpy().mean(), fontdict={'size': 15})
        plt.text(-.5, 2, 'D score= %.2f (-1.38 for G to converge)' % -D_loss.data.numpy(), fontdict={'size': 15})
        plt.ylim((0, 3));plt.legend(loc='upper right', fontsize=12);plt.draw();plt.pause(0.01)
        plt.show()
```


![png](https://shinkeika.github.io/images/output_93_0.png)



![png](https://shinkeika.github.io/images/output_93_1.png)



![png](https://shinkeika.github.io/images/output_93_2.png)



![png](https://shinkeika.github.io/images/output_93_3.png)



![png](https://shinkeika.github.io/images/output_93_4.png)



![png](https://shinkeika.github.io/images/output_93_5.png)



![png](https://shinkeika.github.io/images/output_93_6.png)



![png](https://shinkeika.github.io/images/output_93_7.png)



![png](https://shinkeika.github.io/images/output_93_8.png)



![png](https://shinkeika.github.io/images/output_93_9.png)


#### Dynamic


```python
import torch
from torch import nn
from torch.autograd import Variable
import numpy as np
import matplotlib.pyplot as plt

torch.manual_seed(1)    # reproducible

# Hyper Parameters
INPUT_SIZE = 1          # rnn input size / image width
LR = 0.02      
```


```python
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.RNN(
            input_size=1,
            hidden_size=32,     # rnn hidden unit
            num_layers=1,       # number of rnn layer
            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h_state):
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, https://shinkeika.github.io/images/output_size)
        r_out, h_state = self.rnn(x, h_state)

        outs = []                                   # this is where you can find torch is dynamic
        for time_step in range(r_out.size(1)):      # calculate output for each time step
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state
```


```python
rnn = RNN()
print(rnn)

optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters
loss_func = nn.MSELoss() 
```

    RNN(
      (rnn): RNN(1, 32, batch_first=True)
      (out): Linear(in_features=32, out_features=1, bias=True)
    )



```python
h_state = None   # for initial hidden state

plt.figure(1, figsize=(12, 5))
plt.ion()   # continuously plot

########################  Below is different #########################

################ static time steps ##########
# for step in range(60):
#     start, end = step * np.pi, (step+1)*np.pi   # time steps
#     # use sin predicts cos
#     steps = np.linspace(start, end, 10, dtype=np.float32)

################ dynamic time steps #########
step = 0
for i in range(60):
    dynamic_steps = np.random.randint(1, 4)  # has random time steps
    start, end = step * np.pi, (step + dynamic_steps) * np.pi  # different time steps length
    step += dynamic_steps

    # use sin predicts cos
    steps = np.linspace(start, end, 10 * dynamic_steps, dtype=np.float32)

#######################  Above is different ###########################

    print(len(steps))       # print how many time step feed to RNN

    x_np = np.sin(steps)    # float32 for converting torch FloatTensor
    y_np = np.cos(steps)

    x = Variable(torch.from_numpy(x_np[np.newaxis, :, np.newaxis]))    # shape (batch, time_step, input_size)
    y = Variable(torch.from_numpy(y_np[np.newaxis, :, np.newaxis]))

    prediction, h_state = rnn(x, h_state)   # rnn output
    # !! next step is important !!
    h_state = Variable(h_state.data)        # repack the hidden state, break the connection from last iteration

    loss = loss_func(prediction, y)         # cross entropy loss
    optimizer.zero_grad()                   # clear gradients for this training step
    loss.backward()                         # backpropagation, compute gradients
    optimizer.step()                        # apply gradients

    # plotting
    plt.plot(steps, y_np.flatten(), 'r-')
    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')
    plt.draw()
    plt.pause(0.05)

plt.ioff()
plt.show()
```

    10


    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_98_2.png)


    10



![png](https://shinkeika.github.io/images/output_98_4.png)


    20



![png](https://shinkeika.github.io/images/output_98_6.png)


    10



![png](https://shinkeika.github.io/images/output_98_8.png)


    20



![png](https://shinkeika.github.io/images/output_98_10.png)


    20



![png](https://shinkeika.github.io/images/output_98_12.png)


    30



![png](https://shinkeika.github.io/images/output_98_14.png)


    30



![png](https://shinkeika.github.io/images/output_98_16.png)


    10



![png](https://shinkeika.github.io/images/output_98_18.png)


    10



![png](https://shinkeika.github.io/images/output_98_20.png)


    20



![png](https://shinkeika.github.io/images/output_98_22.png)


    30



![png](https://shinkeika.github.io/images/output_98_24.png)


    20



![png](https://shinkeika.github.io/images/output_98_26.png)


    20



![png](https://shinkeika.github.io/images/output_98_28.png)


    30



![png](https://shinkeika.github.io/images/output_98_30.png)


    10



![png](https://shinkeika.github.io/images/output_98_32.png)


    20



![png](https://shinkeika.github.io/images/output_98_34.png)


    10



![png](https://shinkeika.github.io/images/output_98_36.png)


    30



![png](https://shinkeika.github.io/images/output_98_38.png)


    30



![png](https://shinkeika.github.io/images/output_98_40.png)


    10



![png](https://shinkeika.github.io/images/output_98_42.png)


    30



![png](https://shinkeika.github.io/images/output_98_44.png)


    30



![png](https://shinkeika.github.io/images/output_98_46.png)


    10



![png](https://shinkeika.github.io/images/output_98_48.png)


    10



![png](https://shinkeika.github.io/images/output_98_50.png)


    20



![png](https://shinkeika.github.io/images/output_98_52.png)


    30



![png](https://shinkeika.github.io/images/output_98_54.png)


    20



![png](https://shinkeika.github.io/images/output_98_56.png)


    10



![png](https://shinkeika.github.io/images/output_98_58.png)


    10



![png](https://shinkeika.github.io/images/output_98_60.png)


    20



![png](https://shinkeika.github.io/images/output_98_62.png)


    30



![png](https://shinkeika.github.io/images/output_98_64.png)


    30



![png](https://shinkeika.github.io/images/output_98_66.png)


    20



![png](https://shinkeika.github.io/images/output_98_68.png)


    10



![png](https://shinkeika.github.io/images/output_98_70.png)


    10



![png](https://shinkeika.github.io/images/output_98_72.png)


    30



![png](https://shinkeika.github.io/images/output_98_74.png)


    20



![png](https://shinkeika.github.io/images/output_98_76.png)


    30



![png](https://shinkeika.github.io/images/output_98_78.png)


    20



![png](https://shinkeika.github.io/images/output_98_80.png)


    30



![png](https://shinkeika.github.io/images/output_98_82.png)


    30



![png](https://shinkeika.github.io/images/output_98_84.png)


    20



![png](https://shinkeika.github.io/images/output_98_86.png)


    10



![png](https://shinkeika.github.io/images/output_98_88.png)


    10



![png](https://shinkeika.github.io/images/output_98_90.png)


    10



![png](https://shinkeika.github.io/images/output_98_92.png)


    20



![png](https://shinkeika.github.io/images/output_98_94.png)


    10



![png](https://shinkeika.github.io/images/output_98_96.png)


    30



![png](https://shinkeika.github.io/images/output_98_98.png)


    10



![png](https://shinkeika.github.io/images/output_98_100.png)


    30



![png](https://shinkeika.github.io/images/output_98_102.png)


    20



![png](https://shinkeika.github.io/images/output_98_104.png)


    10



![png](https://shinkeika.github.io/images/output_98_106.png)


    20



![png](https://shinkeika.github.io/images/output_98_108.png)


    10



![png](https://shinkeika.github.io/images/output_98_110.png)


    10



![png](https://shinkeika.github.io/images/output_98_112.png)


    20



![png](https://shinkeika.github.io/images/output_98_114.png)


    20



![png](https://shinkeika.github.io/images/output_98_116.png)


    30



![png](https://shinkeika.github.io/images/output_98_118.png)


    10



![png](https://shinkeika.github.io/images/output_98_120.png)


#### GPU


```python
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.utils.data as Data
import torchvision

torch.manual_seed(1)

import matplotlib.pyplot as plt
%matplotlib inline
```


```python
EPOCH = 1
BATCH_SIZE = 50
LR = 0.001
DOWNLOAD_MNIST = False
```


```python
train_data = torchvision.datasets.MNIST(
    root='./mnist/', 
    train=True, 
    transform=torchvision.transforms.ToTensor(), 
    download=DOWNLOAD_MNIST,)

train_loader = Data.DataLoader(
    dataset=train_data, 
    batch_size=BATCH_SIZE, 
    shuffle=True)

test_data = torchvision.datasets.MNIST(
    root='./mnist/', train=False)

# !!!!!!!! Change in here !!!!!!!!! #
test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1)).type(torch.FloatTensor)[:2000].cuda()/255.   # Tensor on GPU
test_y = test_data.test_labels[:2000].cuda()
```


```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),                      
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2),)
        self.conv2 = nn.Sequential(
            nn.Conv2d(16, 32, 5, 1, 2), 
            nn.ReLU(), 
            nn.MaxPool2d(2),)
        self.out = nn.Linear(32 * 7 * 7, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)
        output = self.out(x)
        return output
```


```python
cnn = CNN()

# !!!!!!!! Change in here !!!!!!!!! #
cnn.cuda()
```


```python
optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)
loss_func = nn.CrossEntropyLoss()

losses_his = []
for epoch in range(EPOCH):
    for step, (x, y) in enumerate(train_loader):

        # !!!!!!!! Change in here !!!!!!!!! #
        b_x = Variable(x).cuda()    # Tensor on GPU
        b_y = Variable(y).cuda()    # Tensor on GPU

        output = cnn(b_x)
        loss = loss_func(output, b_y)
        losses_his.append(loss.data[0])
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if step % 50 == 0:
            test_output = cnn(test_x)

            # !!!!!!!! Change in here !!!!!!!!! #
            pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()  # move the computation in GPU

            accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)
            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)
```


```python
# !!!!!!!! Change in here !!!!!!!!! #
test_output = cnn(test_x[:10])
pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze() # move the computation in GPU

print(pred_y, 'prediction number')
print(test_y[:10], 'real number')
```

#### Dropout


```python
import torch
from torch.autograd import Variable
import matplotlib.pyplot as plt
%matplotlib inline

torch.manual_seed(1)    # reproducible
```




    <torch._C.Generator at 0x10608f5b0>




```python
N_SAMPLES = 20
N_HIDDEN = 300
```


```python
# training data
x = torch.unsqueeze(torch.linspace(-1, 1, N_SAMPLES), 1)
y = x + 0.3*torch.normal(torch.zeros(N_SAMPLES, 1), torch.ones(N_SAMPLES, 1))
x, y = Variable(x), Variable(y)

# test data
test_x = torch.unsqueeze(torch.linspace(-1, 1, N_SAMPLES), 1)
test_y = test_x + 0.3*torch.normal(torch.zeros(N_SAMPLES, 1), torch.ones(N_SAMPLES, 1))
test_x, test_y = Variable(test_x, volatile=True), Variable(test_y, volatile=True)

# show data
plt.scatter(x.data.numpy(), y.data.numpy(), c='magenta', s=50, alpha=0.5, label='train')
plt.scatter(test_x.data.numpy(), test_y.data.numpy(), c='cyan', s=50, alpha=0.5, label='test')
plt.legend(loc='upper left')
plt.ylim((-2.5, 2.5))
plt.show()
```

    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
      if __name__ == '__main__':
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0.0, flags=flags)
    /Users/shinkeika/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.
      font.set_text(s, 0, flags=flags)



![png](https://shinkeika.github.io/images/output_110_1.png)



```python
net_overfitting = torch.nn.Sequential(
    torch.nn.Linear(1, N_HIDDEN),
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, N_HIDDEN),
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, 1),
)

net_dropped = torch.nn.Sequential(
    torch.nn.Linear(1, N_HIDDEN),
    torch.nn.Dropout(0.5),  # drop 50% of the neuron
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, N_HIDDEN),
    torch.nn.Dropout(0.5),  # drop 50% of the neuron
    torch.nn.ReLU(),
    torch.nn.Linear(N_HIDDEN, 1),
)
```


```python
print(net_overfitting)  # net architecture
print(net_dropped)
```

    Sequential(
      (0): Linear(in_features=1, out_features=300, bias=True)
      (1): ReLU()
      (2): Linear(in_features=300, out_features=300, bias=True)
      (3): ReLU()
      (4): Linear(in_features=300, out_features=1, bias=True)
    )
    Sequential(
      (0): Linear(in_features=1, out_features=300, bias=True)
      (1): Dropout(p=0.5, inplace=False)
      (2): ReLU()
      (3): Linear(in_features=300, out_features=300, bias=True)
      (4): Dropout(p=0.5, inplace=False)
      (5): ReLU()
      (6): Linear(in_features=300, out_features=1, bias=True)
    )



```python
optimizer_ofit = torch.optim.Adam(net_overfitting.parameters(), lr=0.01)
optimizer_drop = torch.optim.Adam(net_dropped.parameters(), lr=0.01)
loss_func = torch.nn.MSELoss()
```


```python
for t in range(500):
    pred_ofit = net_overfitting(x)
    pred_drop = net_dropped(x)
    loss_ofit = loss_func(pred_ofit, y)
    loss_drop = loss_func(pred_drop, y)

    optimizer_ofit.zero_grad()
    optimizer_drop.zero_grad()
    loss_ofit.backward()
    loss_drop.backward()
    optimizer_ofit.step()
    optimizer_drop.step()

    if t % 10 == 0:
        # change to eval mode in order to fix drop out effect
        net_overfitting.eval()
        net_dropped.eval()  # parameters for dropout differ from train mode

        # plotting
        plt.cla()
        test_pred_ofit = net_overfitting(test_x)
        test_pred_drop = net_dropped(test_x)
        plt.scatter(x.data.numpy(), y.data.numpy(), c='magenta', s=50, alpha=0.3, label='train')
        plt.scatter(test_x.data.numpy(), test_y.data.numpy(), c='cyan', s=50, alpha=0.3, label='test')
        plt.plot(test_x.data.numpy(), test_pred_ofit.data.numpy(), 'r-', lw=3, label='overfitting')
        plt.plot(test_x.data.numpy(), test_pred_drop.data.numpy(), 'b--', lw=3, label='dropout(50%)')
        plt.text(0, -1.2, 'overfitting loss=%.4f' % loss_func(test_pred_ofit, test_y).data.numpy(), fontdict={'size': 20, 'color':  'red'})
        plt.text(0, -1.5, 'dropout loss=%.4f' % loss_func(test_pred_drop, test_y).data.numpy(), fontdict={'size': 20, 'color': 'blue'})
        plt.legend(loc='upper left'); plt.ylim((-2.5, 2.5));plt.pause(0.1)

        # change back to train mode
        net_overfitting.train()
        net_dropped.train()

plt.ioff()
plt.show()
```


![png](https://shinkeika.github.io/images/output_114_0.png)



![png](https://shinkeika.github.io/images/output_114_1.png)



![png](https://shinkeika.github.io/images/output_114_2.png)



![png](https://shinkeika.github.io/images/output_114_3.png)



![png](https://shinkeika.github.io/images/output_114_4.png)



![png](https://shinkeika.github.io/images/output_114_5.png)



![png](https://shinkeika.github.io/images/output_114_6.png)



![png](https://shinkeika.github.io/images/output_114_7.png)



![png](https://shinkeika.github.io/images/output_114_8.png)



![png](https://shinkeika.github.io/images/output_114_9.png)



![png](https://shinkeika.github.io/images/output_114_10.png)



![png](https://shinkeika.github.io/images/output_114_11.png)



![png](https://shinkeika.github.io/images/output_114_12.png)



![png](https://shinkeika.github.io/images/output_114_13.png)



![png](https://shinkeika.github.io/images/output_114_14.png)



![png](https://shinkeika.github.io/images/output_114_15.png)



![png](https://shinkeika.github.io/images/output_114_16.png)



![png](https://shinkeika.github.io/images/output_114_17.png)



![png](https://shinkeika.github.io/images/output_114_18.png)



![png](https://shinkeika.github.io/images/output_114_19.png)



![png](https://shinkeika.github.io/images/output_114_20.png)



![png](https://shinkeika.github.io/images/output_114_21.png)



![png](https://shinkeika.github.io/images/output_114_22.png)



![png](https://shinkeika.github.io/images/output_114_23.png)



![png](https://shinkeika.github.io/images/output_114_24.png)



![png](https://shinkeika.github.io/images/output_114_25.png)



![png](https://shinkeika.github.io/images/output_114_26.png)



![png](https://shinkeika.github.io/images/output_114_27.png)



![png](https://shinkeika.github.io/images/output_114_28.png)



![png](https://shinkeika.github.io/images/output_114_29.png)



![png](https://shinkeika.github.io/images/output_114_30.png)



![png](https://shinkeika.github.io/images/output_114_31.png)



![png](https://shinkeika.github.io/images/output_114_32.png)



![png](https://shinkeika.github.io/images/output_114_33.png)



![png](https://shinkeika.github.io/images/output_114_34.png)



![png](https://shinkeika.github.io/images/output_114_35.png)



![png](https://shinkeika.github.io/images/output_114_36.png)



![png](https://shinkeika.github.io/images/output_114_37.png)



![png](https://shinkeika.github.io/images/output_114_38.png)



![png](https://shinkeika.github.io/images/output_114_39.png)



![png](https://shinkeika.github.io/images/output_114_40.png)



![png](https://shinkeika.github.io/images/output_114_41.png)



![png](https://shinkeika.github.io/images/output_114_42.png)



![png](https://shinkeika.github.io/images/output_114_43.png)



![png](https://shinkeika.github.io/images/output_114_44.png)



![png](https://shinkeika.github.io/images/output_114_45.png)



![png](https://shinkeika.github.io/images/output_114_46.png)



![png](https://shinkeika.github.io/images/output_114_47.png)



![png](https://shinkeika.github.io/images/output_114_48.png)



![png](https://shinkeika.github.io/images/output_114_49.png)


#### batch_normalization


```python
import torch
from torch import nn
from torch.nn import init
import torch.utils.data as Data
import matplotlib.pyplot as plt
import numpy as np

# torch.manual_seed(1)    # reproducible
# np.random.seed(1)

# Hyper parameters
N_SAMPLES = 2000
BATCH_SIZE = 64
EPOCH = 12
LR = 0.03
N_HIDDEN = 8
ACTIVATION = torch.tanh
B_INIT = -0.2   # use a bad bias constant initializer

# training data
x = np.linspace(-7, 10, N_SAMPLES)[:, np.newaxis]
noise = np.random.normal(0, 2, x.shape)
y = np.square(x) - 5 + noise

# test data
test_x = np.linspace(-7, 10, 200)[:, np.newaxis]
noise = np.random.normal(0, 2, test_x.shape)
test_y = np.square(test_x) - 5 + noise

train_x, train_y = torch.from_numpy(x).float(), torch.from_numpy(y).float()
test_x = torch.from_numpy(test_x).float()
test_y = torch.from_numpy(test_y).float()

train_dataset = Data.TensorDataset(train_x, train_y)
train_loader = Data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2,)

# show data
plt.scatter(train_x.numpy(), train_y.numpy(), c='#FF9359', s=50, alpha=0.2, label='train')
plt.legend(loc='upper left')


class Net(nn.Module):
    def __init__(self, batch_normalization=False):
        super(Net, self).__init__()
        self.do_bn = batch_normalization
        self.fcs = []
        self.bns = []
        self.bn_input = nn.BatchNorm1d(1, momentum=0.5)   # for input data

        for i in range(N_HIDDEN):               # build hidden layers and BN layers
            input_size = 1 if i == 0 else 10
            fc = nn.Linear(input_size, 10)
            setattr(self, 'fc%i' % i, fc)       # IMPORTANT set layer to the Module
            self._set_init(fc)                  # parameters initialization
            self.fcs.append(fc)
            if self.do_bn:
                bn = nn.BatchNorm1d(10, momentum=0.5)
                setattr(self, 'bn%i' % i, bn)   # IMPORTANT set layer to the Module
                self.bns.append(bn)

        self.predict = nn.Linear(10, 1)         # output layer
        self._set_init(self.predict)            # parameters initialization

    def _set_init(self, layer):
        init.normal_(layer.weight, mean=0., std=.1)
        init.constant_(layer.bias, B_INIT)

    def forward(self, x):
        pre_activation = [x]
        if self.do_bn: x = self.bn_input(x)     # input batch normalization
        layer_input = [x]
        for i in range(N_HIDDEN):
            x = self.fcs[i](x)
            pre_activation.append(x)
            if self.do_bn: x = self.bns[i](x)   # batch normalization
            x = ACTIVATION(x)
            layer_input.append(x)
        out = self.predict(x)
        return out, layer_input, pre_activation

nets = [Net(batch_normalization=False), Net(batch_normalization=True)]

# print(*nets)    # print net architecture

opts = [torch.optim.Adam(net.parameters(), lr=LR) for net in nets]

loss_func = torch.nn.MSELoss()


def plot_histogram(l_in, l_in_bn, pre_ac, pre_ac_bn):
    for i, (ax_pa, ax_pa_bn, ax, ax_bn) in enumerate(zip(axs[0, :], axs[1, :], axs[2, :], axs[3, :])):
        [a.clear() for a in [ax_pa, ax_pa_bn, ax, ax_bn]]
        if i == 0:
            p_range = (-7, 10);the_range = (-7, 10)
        else:
            p_range = (-4, 4);the_range = (-1, 1)
        ax_pa.set_title('L' + str(i))
        ax_pa.hist(pre_ac[i].data.numpy().ravel(), bins=10, range=p_range, color='#FF9359', alpha=0.5);ax_pa_bn.hist(pre_ac_bn[i].data.numpy().ravel(), bins=10, range=p_range, color='#74BCFF', alpha=0.5)
        ax.hist(l_in[i].data.numpy().ravel(), bins=10, range=the_range, color='#FF9359');ax_bn.hist(l_in_bn[i].data.numpy().ravel(), bins=10, range=the_range, color='#74BCFF')
        for a in [ax_pa, ax, ax_pa_bn, ax_bn]: a.set_yticks(());a.set_xticks(())
        ax_pa_bn.set_xticks(p_range);ax_bn.set_xticks(the_range)
        axs[0, 0].set_ylabel('PreAct');axs[1, 0].set_ylabel('BN PreAct');axs[2, 0].set_ylabel('Act');axs[3, 0].set_ylabel('BN Act')
    plt.pause(0.01)


if __name__ == "__main__":
    f, axs = plt.subplots(4, N_HIDDEN + 1, figsize=(10, 5))
    plt.ion()  # something about plotting
    plt.show()

    # training
    losses = [[], []]  # recode loss for two networks

    for epoch in range(EPOCH):
        print('Epoch: ', epoch)
        layer_inputs, pre_acts = [], []
        for net, l in zip(nets, losses):
            net.eval()              # set eval mode to fix moving_mean and moving_var
            pred, layer_input, pre_act = net(test_x)
            l.append(loss_func(pred, test_y).data.item())
            layer_inputs.append(layer_input)
            pre_acts.append(pre_act)
            net.train()             # free moving_mean and moving_var
        plot_histogram(*layer_inputs, *pre_acts)     # plot histogram

        for step, (b_x, b_y) in enumerate(train_loader):
            for net, opt in zip(nets, opts):     # train for each network
                pred, _, _ = net(b_x)
                loss = loss_func(pred, b_y)
                opt.zero_grad()
                loss.backward()
                opt.step()    # it will also learns the parameters in Batch Normalization

    plt.ioff()

    # plot training loss
    plt.figure(2)
    plt.plot(losses[0], c='#FF9359', lw=3, label='Original')
    plt.plot(losses[1], c='#74BCFF', lw=3, label='Batch Normalization')
    plt.xlabel('step');plt.ylabel('test loss');plt.ylim((0, 2000));plt.legend(loc='best')

    # evaluation
    # set net to eval mode to freeze the parameters in batch normalization layers
    [net.eval() for net in nets]    # set eval mode to fix moving_mean and moving_var
    preds = [net(test_x)[0] for net in nets]
    plt.figure(3)
    plt.plot(test_x.data.numpy(), preds[0].data.numpy(), c='#FF9359', lw=4, label='Original')
    plt.plot(test_x.data.numpy(), preds[1].data.numpy(), c='#74BCFF', lw=4, label='Batch Normalization')
    plt.scatter(test_x.data.numpy(), test_y.data.numpy(), c='r', s=50, alpha=0.2, label='train')
    plt.legend(loc='best')
    plt.show()
```


![png](https://shinkeika.github.io/images/output_116_0.png)



![png](https://shinkeika.github.io/images/output_116_1.png)


    Epoch:  0
    Epoch:  1
    Epoch:  2
    Epoch:  3
    Epoch:  4
    Epoch:  5
    Epoch:  6
    Epoch:  7
    Epoch:  8
    Epoch:  9
    Epoch:  10
    Epoch:  11



![png](https://shinkeika.github.io/images/output_116_3.png)



![png](https://shinkeika.github.io/images/output_116_4.png)



```python

```
